{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hBhehsaWjj7B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import class_weight\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional, SpatialDropout1D, BatchNormalization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Krn6kYKcjpiD",
        "outputId": "9e980b76-f95f-48d4-e134-c5a42a4d35cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"customer_feedback.csv\")\n"
      ],
      "metadata": {
        "id": "uba8mvM9jymo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_sentiment(score):\n",
        "    if score <= 2:\n",
        "        return 0\n",
        "    elif score == 3:\n",
        "        return 1\n",
        "    else:\n",
        "        return 2\n",
        "\n",
        "df[\"Sentiment\"] = df[\"FeedbackScore\"].apply(map_sentiment)\n"
      ],
      "metadata": {
        "id": "FElrJalnj8kG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = str(text).lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
        "    text = re.sub(r'(.)\\1{2,}', r'\\1', text)  # reduce repeated chars\n",
        "    tokens = text.split()\n",
        "    tokens = [lemmatizer.lemmatize(w, pos='v') for w in tokens if w not in stop_words and len(w) > 2]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "df[\"CleanedText\"] = df[\"FeedbackText\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "xhbIw85xkA0r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df[\"CleanedText\"].tolist()\n",
        "labels = df[\"Sentiment\"].tolist()\n",
        "\n",
        "max_words = 20000\n",
        "max_len = 250\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(texts)\n",
        "sequences = tokenizer.texts_to_sequences(texts)\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)"
      ],
      "metadata": {
        "id": "7h2r8Vo2kFY1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    padded_sequences, labels, test_size=0.2, stratify=labels, random_state=42\n",
        ")\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=3)\n",
        "y_test_cat = to_categorical(y_test, num_classes=3)"
      ],
      "metadata": {
        "id": "D0SsjU34kM29"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
        "class_weights = dict(enumerate(weights))"
      ],
      "metadata": {
        "id": "GrMjL21TkOlg"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=256, input_length=max_len),\n",
        "    SpatialDropout1D(0.3),\n",
        "    Bidirectional(LSTM(96, return_sequences=True)),\n",
        "    Dropout(0.4),\n",
        "    BatchNormalization(),\n",
        "    Bidirectional(LSTM(48)),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g52YM7A2kVSX",
        "outputId": "a8a5ea16-c272-4709-d49a-29d87a048572"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "kqMjOAxnkXR8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=5, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(patience=3, factor=0.5)\n",
        "]"
      ],
      "metadata": {
        "id": "TwRw4w2PkfWX"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "history = model.fit(\n",
        "    X_train, y_train_cat,\n",
        "    epochs=30,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_test, y_test_cat),\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjMFOH94kjIf",
        "outputId": "b55ea86c-5507-4737-964b-f1aefc40b05a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.3656 - loss: 1.0957 - val_accuracy: 0.4500 - val_loss: 1.0968 - learning_rate: 0.0010\n",
            "Epoch 2/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.4539 - loss: 1.0688 - val_accuracy: 0.4500 - val_loss: 1.0967 - learning_rate: 0.0010\n",
            "Epoch 3/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 0.4125 - loss: 1.1223 - val_accuracy: 0.4500 - val_loss: 1.0957 - learning_rate: 0.0010\n",
            "Epoch 4/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.3492 - loss: 1.1034 - val_accuracy: 0.4500 - val_loss: 1.0939 - learning_rate: 0.0010\n",
            "Epoch 5/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - accuracy: 0.3969 - loss: 1.0914 - val_accuracy: 0.4500 - val_loss: 1.0934 - learning_rate: 0.0010\n",
            "Epoch 6/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step - accuracy: 0.4883 - loss: 1.0199 - val_accuracy: 0.4500 - val_loss: 1.0946 - learning_rate: 0.0010\n",
            "Epoch 7/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 0.4906 - loss: 0.9829 - val_accuracy: 0.5000 - val_loss: 1.0962 - learning_rate: 0.0010\n",
            "Epoch 8/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.6641 - loss: 0.8738 - val_accuracy: 0.4000 - val_loss: 1.0977 - learning_rate: 0.0010\n",
            "Epoch 9/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 957ms/step - accuracy: 0.7648 - loss: 0.7534 - val_accuracy: 0.4000 - val_loss: 1.0971 - learning_rate: 5.0000e-04\n",
            "Epoch 10/30\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8250 - loss: 0.6776 - val_accuracy: 0.3500 - val_loss: 1.0951 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "loss, accuracy = model.evaluate(X_test, y_test_cat)\n",
        "print(f\"\\n✅ Final Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "huRaCLJakx_6",
        "outputId": "c42646bd-58da-43f4-fee7-5bce140f996c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.4500 - loss: 1.0934\n",
            "\n",
            "✅ Final Test Accuracy: 45.00%\n"
          ]
        }
      ]
    }
  ]
}